---
title: "Data Mining II — D212"
author: "Tyson Biegler"
sbutitle: "Student ID: 012170282"
format: html
editor: visual
---

**Part I: Research Question**

**A1:** Can we identify distinct groups of customers based on their tenure and bandwidth GB usage, using K-means clustering?

**A2:** The goal of this analysis is to group customers into distinct clusters based on their tenure and bandwidth GB usage to identify patterns that could help better understand customer behavior.

**Part II: Technique Justification**

**B1:** l will be using k-means clustering with two continuous variables, `Tenure` and `Bandwidth_GB_Year`, to group customers into clusters based on their similarity. The k-means algorithm itterates through each customer and assigns them to the nearest cluster based on euclidean distance and updates the centroids. It repeats this process until the clusters don't change anymore. This ensures that customers within a cluster are more similar to each other than to those in other clusters. The expected outcome is to identify distinct customer groups, such as long-time customers with low bandwidth usage or newer customers with high bandwidth usage.

**B2:** On main assumption of k-means clustering is that the clusters are spherical (***geeksforgeeks, 2023***), meaning that the spread of the data points is similar in all directions within each cluster. This is important because k-means uses the euclidean distance between points to determine the cluster assignment, as mentioned in B1, and if the clusters are spherical then the distance between points is roughly the same.

```{r echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
#Student ID: 012170282

library(tidyverse)    # For data manipulation and visualization (includes dplyr, ggplot2)
library(cluster)      # For silhouette analysis to evaluate cluster quality
library(factoextra)   # Elbow plot


# Initial setup -----------------------------------------------------------
setwd('C:/Users/tyson/Documents/GitHub/WGU_MSDA_Portfolio/Data mining II - D212/Raw')


# Data acquisition --------------------------------------------------------
churn <- read_csv("churn_clean.csv")

# Data exploration --------------------------------------------------------
glimpse(churn)

#Checking for missing or duplicate values
sum(is.na(churn))
sum(duplicated(churn))

head(churn)

# Preparing the data ------------------------------------------------------

churn <- churn[, c("Tenure", "Bandwidth_GB_Year")]  #picked only 2 variables (Kamara, 2023)

```

```{r echo=FALSE}
bandwidth_range <- range(churn$Bandwidth_GB_Year)
tenure_range <- range(churn$Tenure)

cat('The range of Bandwidth_GB_Year is',bandwidth_range)
cat('The range of Tenure is',tenure_range)
```

```{r echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
#Student ID: 012170282

library(tidyverse)    # For data manipulation and visualization (includes dplyr, ggplot2)
library(cluster)      # For silhouette analysis to evaluate cluster quality
library(factoextra)   # Elbow plot


# Initial setup -----------------------------------------------------------
setwd('C:/Users/tyson/Documents/GitHub/WGU_MSDA_Portfolio/Data mining II - D212/Raw')


# Data acquisition --------------------------------------------------------
churn <- read_csv("churn_clean.csv")

# Data exploration --------------------------------------------------------
glimpse(churn)

#Checking for missing or duplicate values
sum(is.na(churn))
sum(duplicated(churn))

head(churn)

# Preparing the data ------------------------------------------------------

churn <- churn[, c("Tenure", "Bandwidth_GB_Year")]  #picked only 2 variables (Kamara, 2023)

#scaling the data
churn <- as.data.frame(scale(churn))

glimpse(churn)

# Plots -------------------------------------------------------------------

ggplot(churn, aes(x = Tenure)) +
  geom_histogram(binwidth = 0.5, fill = "#0072B2", color = "black") +
  theme_minimal() +
  labs(title = "Distribution of Tenure", x = "Tenure", y = "Count")

ggplot(churn, aes(x = Bandwidth_GB_Year)) +
  geom_histogram(binwidth = 0.5, fill = "#0072B2", color = "black") +
  theme_minimal() +
  labs(title = "Distribution of Bandwidth_GB_Year", x = "Bandwidth_GB_Year", y = "Count")


# Create model ------------------------------------------------------------
set.seed(1234)

#scree plot to find the elbow and  best K value
fviz_nbclust(churn, kmeans, method = "wss") + # SOURCE: (Bobbitt,2022)
  labs(title = "Elbow Method for Best k")

km <- kmeans(churn, centers = 2, nstart = 20)

# k means with 2 clusters based on the elbow plot
print(km$centers)

#creating a datafram with the cluster assignments so i can plot 
final_data <- cbind(churn, cluster = km$cluster)

head(final_data)

# Export cleaned data to CSV ---------------------------------------------------
write.csv(final_data, "C:/Users/tyson/Documents/GitHub/WGU_MSDA_Portfolio/Data mining II - D212/Cleaned/Task1/churn_cleaned_data.csv", row.names = FALSE)

ggplot(final_data, aes(x = Tenure, y = Bandwidth_GB_Year, color = as.factor(cluster))) +
  geom_point(alpha = 0.5) +
  theme_minimal() +
  scale_color_manual(values = c("#E69F00", "#0072B2")) +
  labs(title = "Scatter Plot of Tenure vs. Bandwidth_GB_Year by Cluster", 
       x = "Tenure", 
       y = "Bandwidth_GB_Year", 
       color = "Cluster")


#silhouette score -1 not good to +1 good. 
sil <- silhouette(km$cluster, dist(churn))
fviz_silhouette(sil)

```

**B3:** In this analysis, I used `Tidyverse` for basic data manipulation and visualizations. `Cluster` was used for cluster analysis. Specifically I used `silhouette()` to calculate the silhouette score that measures the quality of the k-means clustering. Lastly I used `factoextra()` to visualize the scree plot for finding the optimal k value, plotting the clusters themselves, and for plotting the silhouette scores.

**Part III: Data Preparation**

**C1:** One pre-processing goal is to scale the variables so that they have equal weight in the k-means clustering algorithm because the range on the values is vastly different, as noted in section B2. So it is essential that these variables are properly scaled.

**C2:** In his D212 webinar, Dr Kamara suggests that two variables is enough for for this assessment (***Kamara, 2023***). Therefore, I have chosen to investigate `Bandwidth_GB_Year` and `Tenure`. Tenure indicates customer stability and loyalty while bandwidth usage displays the customer's usage of the companies services. When analyzing these together with k-means, it becomes possible to identify the distinct groups and analyze these customers' behavior.

C3: I picked two numeric variables, `Tenure` and `Bandwidth_GB_Year` , and then I scaled them using `scale()`.

```{r echo=FALSE, message=FALSE, warning=FALSE}

ggplot(churn, aes(x = Tenure)) +
  geom_histogram(binwidth = 0.5, fill = "#0072B2", color = "black") +
  theme_minimal() +
  labs(title = "Distribution of Tenure", x = "Tenure", y = "Count")

ggplot(churn, aes(x = Bandwidth_GB_Year)) +
  geom_histogram(binwidth = 0.5, fill = "#0072B2", color = "black") +
  theme_minimal() +
  labs(title = "Distribution of Bandwidth_GB_Year", x = "Bandwidth_GB_Year", y = "Count")
```

```{r echo=TRUE, warning=FALSE, eval=FALSE}
# Preparing the data ------------------------------------------------------

churn <- churn[, c("Tenure", "Bandwidth_GB_Year")]  #picked only 2 variables (Kamara, 2023)

#scaling the data
churn <- as.data.frame(scale(churn))
```

**C4:** A copy of the cleaned dataset will be provided in the submission files and is named "***churn_cleaned_data.csv***". Below is a sample of the cleaned dataset. The output shows the standardized values where each variable has a mean of 0 and a standard deviation of 1.

```{r echo=FALSE, message=FALSE, warning=FALSE}

head(churn)
```

**Part IV: Analysis**

**D1:** To determine the optimal number of clusters, I used the elbow method. The scree plot below plots the total within sum of squares (WSS) and the number of clusters. From the plot it appears that the WSS change slows significantly after just two clusters. There is large changes from one to two clusters, and a small change from two to four, but after four clusters the WSS appears to essentially level off. Three or even four clusters could be argued for based on the elbow method. However two clusters seems to be the optimal k value as the remaining clusters appear to be mostly leveled off by the second cluster.

```{r message=FALSE, warning=FALSE}
#scree plot to find the elbow and  best K value
fviz_nbclust(churn, kmeans, method = "wss") + # SOURCE: (Bobbitt,2022)
  labs(title = "Elbow Method for Best k")
```

**D2:** The following code performes the k-means clustering with 4 clusters *(centers = 4)* as mentioned in D1 and an nstart of 20. According to an article from Smith College in 2016, "It is generally recommended to always run K-means clustering with a large value of nstart, such as 20 or 50..." (***Smith College, 2016, under 'K-Means Clustering' section***). So I decided to use 20 as my nstart value.

```{r message=FALSE, warning=FALSE}
km <- kmeans(churn, centers = 2, nstart = 20)
```

**Part V: Data Summary and Implications**

**E1:** The quality of the clusters is evaluated by using a silhouette plot, generated withe `fviz_silhouette()`. The average silhouette width is 0.81, 0.78 for cluster one and 0.84 for cluster two. The silhouette scores range from -1 (bad) to +1 (good). So a width of 0.81 is suggestive of a good quality cluster.

```{r echo=F, message=FALSE, warning=FALSE}
#silhouette score -1 not good to +1 good. 
sil <- silhouette(km$cluster, dist(churn))
fviz_silhouette(sil)
```

**E2:** This k-means algorithm was able to identify two distinct clusters in the data. When I print the cluster centroids it becomes apparent that the clusters are identified as follows:

-   Cluster 1: High Tenure and high Bandwidth usage.

-   Cluster 2: Low Tenure and low Bandwidth usage.

```{r echo=FALSE, message=FALSE, warning=FALSE}
# k means with 2 clusters based on the elbow plot
print(km$centers)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}

ggplot(final_data, aes(x = Tenure, y = Bandwidth_GB_Year, color = as.factor(cluster))) +
  geom_point(alpha = 0.5) +
  theme_minimal() +
  scale_color_manual(values = c("#E69F00", "#0072B2")) +
  labs(title = "Scatter Plot of Tenure vs. Bandwidth_GB_Year by Cluster", 
       x = "Tenure", 
       y = "Bandwidth_GB_Year", 
       color = "Cluster")

```

Because there appears to be a strong correlation between tenure and average bandwidth usage in both clusters suggesting that customers with long tenure tend to use more data per year and customers who have a short tenure use less per year.

**E3:** The main limitation to this analysis is that it only takes into account 2 variables and because of this, it might not capture the full complexity of a customer's behavior. Adding more features would help the algorithm cluster the customer into more accurate groups and allow me to make more accurate recommendations.

**E4:** Because we know that customers in cluster 2 have a low tenure and a low bandwidth usage per year, I recommend that the company investigate further into the reason for their low tenure and focus retention efforts on these customers in cluster 2. In contrast, customers in cluster 1 appear to be happy. They have a long tenure and they are using the internet services as expected. I would recommend that the company offer incentives to these customers that would reward their loyalty.

**Part VI: Demonstration**

**F:** My Panopto video link will be included in my submission files.

**G-H:**  Code Sources:

-   Bobbitt. (2022, September 8). *How to use the elbow method in R to find optimal clusters.* Statology. <https://www.statology.org/elbow-method-in-r/>

-   GeeksforGeeks. (2023, December 9). *Demonstration of K-Means assumptions.* <https://www.geeksforgeeks.org/demonstration-of-k-means-assumptions/>

-   Kamara, K. (2023, March 19). *Data mining II - D212 Webinar* \[Video\]. Western Governors University. <https://wgu.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=afbc9be3-7f3a-48ef-a862-afcb0118b043&query=D212>

-   Smith College. (2016). *10.5.1 K-Means clustering.* Retrieved from <https://www.science.smith.edu/~jcrouser/SDS293/labs/lab16-r.html>
